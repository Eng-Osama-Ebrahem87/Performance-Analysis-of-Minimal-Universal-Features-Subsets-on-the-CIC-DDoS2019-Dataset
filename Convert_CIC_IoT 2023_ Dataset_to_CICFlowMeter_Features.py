

"""
Network Traffic Feature Extractor for CIC-IoT 2023 Dataset
Inspired by CICFlowMeter functionality
Author: Assistant
Date: 2024
"""
import pandas as pd
import numpy as np
import logging
from typing import Tuple, Dict, Any
from scipy import stats
import warnings
warnings.filterwarnings('ignore')
# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
class NetworkFeatureExtractor:
    """
    A class to extract network traffic features similar to CICFlowMeter
    from CIC-IoT 2023 dataset
    """
    def __init__(self, csv_file_path: str):
        """
        Initialize the feature extractor with dataset path
        Args:
            csv_file_path (str): Path to the CSV file containing network data
        """
        self.csv_file_path = csv_file_path
        self.data = None
        self.features_df = None
    def load_data(self) -> bool:
        """
        Load and validate the CSV data
        Returns:
            bool: True if successful, False otherwise
        """
        try:
            logger.info(f"Loading data from {self.csv_file_path}")
            self.data = pd.read_csv(self.csv_file_path)
            # Validate required columns
            required_columns = [
                'flow_duration', 'Header_Length', 'Protocol Type', 'Duration', 
                'Rate', 'Srate', 'Drate', 'fin_flag_number', 'syn_flag_number',
                'rst_flag_number', 'psh_flag_number', 'ack_flag_number',
                'ece_flag_number', 'cwr_flag_number', 'ack_count', 'syn_count',
                'fin_count', 'urg_count', 'rst_count', 'HTTP', 'HTTPS', 'DNS',
                'Telnet', 'SMTP', 'SSH', 'IRC', 'TCP', 'UDP', 'DHCP', 'ARP',
                'ICMP', 'IPv', 'LLC', 'Tot sum', 'Min', 'Max', 'AVG', 'Std',
                'Tot size', 'IAT', 'Number', 'Magnitue', 'Radius', 'Covariance',
                'Variance', 'Weight', 'label'
            ]
            missing_columns = [col for col in required_columns if col not in self.data.columns]
            if missing_columns:
                logger.warning(f"Missing columns: {missing_columns}")
            logger.info(f"Data loaded successfully. Shape: {self.data.shape}")
            return True
        except Exception as e:
            logger.error(f"Error loading data: {e}")
            return False
    def calculate_packet_length_mean(self) -> pd.Series:
        """
        Calculate Packet Length Mean (average size of packets in the flow)
        Returns:
            pd.Series: Packet length mean for each flow
        """
        try:
            # Using AVG column which represents average packet size
            packet_length_mean = self.data['AVG']
            logger.info("Calculated Packet Length Mean")
            return packet_length_mean
        except KeyError:
            logger.warning("AVG column not found, calculating from Tot size and Number")
            return self.data['Tot size'] / self.data['Number']
    def calculate_average_packet_size(self) -> pd.Series:
        """
        Calculate Average Packet Size (similar to packet length mean)
        Returns:
            pd.Series: Average packet size for each flow
        """
        # This is typically the same as packet length mean
        return self.calculate_packet_length_mean()
    def calculate_bwd_packet_length_min(self) -> pd.Series:
        """
        Calculate Backward Packet Length Minimum
        Minimum packet size in the backward direction
        Returns:
            pd.Series: Backward packet length minimum
        """
        try:
            # Using Min column as approximation
            bwd_min = self.data['Min']
            logger.info("Calculated Bwd Packet Length Min")
            return bwd_min
        except KeyError:
            logger.warning("Min column not found, using alternative calculation")
            return pd.Series([0] * len(self.data))
    def calculate_fwd_packets_per_second(self) -> pd.Series:
        """
        Calculate Forward Packets per Second
        Rate of packets in forward direction
        Returns:
            pd.Series: Forward packets per second
        """
        try:
            # Using Srate (Source rate) as forward packets per second
            fwd_pps = self.data['Srate']
            logger.info("Calculated Fwd Packets/s")
            return fwd_pps
        except KeyError:
            logger.warning("Srate column not found, calculating from flow duration")
            return self.data['Number'] / (self.data['flow_duration'] / 1000000)  # Convert to seconds
    def calculate_min_packet_length(self) -> pd.Series:
        """
        Calculate Minimum Packet Length in the flow
        Returns:
            pd.Series: Minimum packet length
        """
        try:
            min_packet_length = self.data['Min']
            logger.info("Calculated Min Packet Length")
            return min_packet_length
        except KeyError:
            logger.warning("Min column not found, using alternative approach")
            return pd.Series([64] * len(self.data))  # Default minimum Ethernet frame size
    def calculate_down_up_ratio(self) -> pd.Series:
        """
        Calculate Download/Upload Ratio
        Ratio of download traffic to upload traffic
        Returns:
            pd.Series: Down/Up ratio
        """
        try:
            # Using Drate (Destination rate) and Srate (Source rate) for ratio
            down_up_ratio = self.data['Drate'] / self.data['Srate']
            # Handle division by zero and infinite values
            down_up_ratio = down_up_ratio.replace([np.inf, -np.inf], 0).fillna(0)
            logger.info("Calculated Down/Up Ratio")
            return down_up_ratio
        except KeyError:
            logger.warning("Drate or Srate columns not found, using default ratio")
            return pd.Series([1.0] * len(self.data))
    def extract_label(self) -> pd.Series:
        """
        Extract the label column for classification
        Returns:
            pd.Series: Label values
        """
        try:
            label = self.data['label']
            logger.info("Extracted labels")
            return label
        except KeyError:
            logger.error("Label column not found")
            return pd.Series(['unknown'] * len(self.data))
    def calculate_all_features(self) -> pd.DataFrame:
        """
        Calculate all required features and create feature dataframe
        Returns:
            pd.DataFrame: DataFrame with all calculated features
        """
        logger.info("Starting feature calculation...")
        features = {
            'Packet_Length_Mean': self.calculate_packet_length_mean(),
            'Average_Packet_Size': self.calculate_average_packet_size(),
            'Bwd_Packet_Length_Min': self.calculate_bwd_packet_length_min(),
            'Fwd_Packets_per_second': self.calculate_fwd_packets_per_second(),
            'Min_Packet_Length': self.calculate_min_packet_length(),
            'Down_Up_Ratio': self.calculate_down_up_ratio(),
            'Label': self.extract_label()
        }
        self.features_df = pd.DataFrame(features)
        # Data cleaning: Handle infinite and NaN values
        self.features_df = self.features_df.replace([np.inf, -np.inf], np.nan)
        self.features_df = self.features_df.fillna(0)
        logger.info(f"Feature extraction completed. Final shape: {self.features_df.shape}")
        return self.features_df
    def get_feature_statistics(self) -> pd.DataFrame:
        """
        Generate descriptive statistics for the extracted features
        Returns:
            pd.DataFrame: Statistics for each feature
        """
        if self.features_df is None:
            logger.warning("No features calculated yet. Run calculate_all_features() first.")
            return pd.DataFrame()
        return self.features_df.describe()
    def save_features(self, output_path: str = 'extracted_features.csv'):
        """
        Save extracted features to CSV file
        Args:
            output_path (str): Path for output CSV file
        """
        if self.features_df is not None:
            self.features_df.to_csv(output_path, index=False)
            logger.info(f"Features saved to {output_path}")
        else:
            logger.warning("No features to save. Run calculate_all_features() first.")
def main():
    """
    Main execution function
    """
    # Configuration
    CSV_FILE_PATH =   r"E:\CIC-IoT 2023\CIC-IoT2023 form kaggle\test.csv"


    OUTPUT_FILE = r"E:\CIC-IoT 2023\CIC-IoT2023 form kaggle\test_with_CIC_Features.csv"

    # Initialize feature extractor
    extractor = NetworkFeatureExtractor(CSV_FILE_PATH)
    # Load data
    if not extractor.load_data():
        logger.error("Failed to load data. Exiting.")
        return
    # Calculate features
    features_df = extractor.calculate_all_features()
    # Display feature statistics
    print("\n=== Feature Statistics ===")
    statistics = extractor.get_feature_statistics()
    print(statistics)
    # Display sample of extracted features
    print("\n=== Sample of Extracted Features ===")
    print(features_df.head(10))
    # Save features to file
    extractor.save_features(OUTPUT_FILE)
    # Display label distribution
    print("\n=== Label Distribution ===")
    label_distribution = features_df['Label'].value_counts()
    print(label_distribution)
    logger.info("Feature extraction process completed successfully!")
if __name__ == "__main__":
    main()


'''

This code provides:
Key Features:
1. Professional Structure: Class-based implementation with proper error handling
2. Comprehensive Logging: Detailed logging for debugging and monitoring
3. Type Hints: Python type annotations for better code clarity
4. Modular Design: Each feature has its own calculation method
5. Data Validation: Checks for missing columns and handles edge cases
6. Statistical Analysis: Provides feature statistics and distributions
Main Components:
路 NetworkFeatureExtractor Class: Main class handling all operations
路 Feature Calculation Methods: Individual methods for each required feature
路 Data Validation: Robust error handling and data cleaning
路 Output Generation: Saves results and provides statistics
Features Calculated:
1. Packet Length Mean: Average packet size in the flow
2. Average Packet Size: Similar to packet length mean
3. Bwd Packet Length Min: Minimum packet size in backward direction
4. Fwd Packets/s: Forward packets per second rate
5. Min Packet Length: Minimum packet length in the flow
6. Down/Up Ratio: Download to upload traffic ratio
7. Label: Classification labels
Usage:
```python
# Initialize and run
extractor = NetworkFeatureExtractor('your_dataset.csv')
extractor.load_data()
features = extractor.calculate_all_features()
extractor.save_features('output.csv')
```
The code is designed to be robust, professional, and easily extensible for additional features or modifications.

'''

